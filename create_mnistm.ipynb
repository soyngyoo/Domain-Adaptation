{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -L -O http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BSR training images\n",
      "Building train set...\n",
      "Processing example 0\n",
      "Processing example 1000\n",
      "Processing example 2000\n",
      "Processing example 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab1_ysy/anaconda3/envs/tf22/lib/python3.6/site-packages/ipykernel_launcher.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example 4000\n",
      "Processing example 5000\n",
      "Processing example 6000\n",
      "Processing example 7000\n",
      "Processing example 8000\n",
      "Processing example 9000\n",
      "Processing example 10000\n",
      "Processing example 11000\n",
      "Processing example 12000\n",
      "Processing example 13000\n",
      "Processing example 14000\n",
      "Processing example 15000\n",
      "Processing example 16000\n",
      "Processing example 17000\n",
      "Processing example 18000\n",
      "Processing example 19000\n",
      "Processing example 20000\n",
      "Processing example 21000\n",
      "Processing example 22000\n",
      "Processing example 23000\n",
      "Processing example 24000\n",
      "Processing example 25000\n",
      "Processing example 26000\n",
      "Processing example 27000\n",
      "Processing example 28000\n",
      "Processing example 29000\n",
      "Processing example 30000\n",
      "Processing example 31000\n",
      "Processing example 32000\n",
      "Processing example 33000\n",
      "Processing example 34000\n",
      "Processing example 35000\n",
      "Processing example 36000\n",
      "Processing example 37000\n",
      "Processing example 38000\n",
      "Processing example 39000\n",
      "Processing example 40000\n",
      "Processing example 41000\n",
      "Processing example 42000\n",
      "Processing example 43000\n",
      "Processing example 44000\n",
      "Processing example 45000\n",
      "Processing example 46000\n",
      "Processing example 47000\n",
      "Processing example 48000\n",
      "Processing example 49000\n",
      "Processing example 50000\n",
      "Processing example 51000\n",
      "Processing example 52000\n",
      "Processing example 53000\n",
      "Processing example 54000\n",
      "Processing example 55000\n",
      "Processing example 56000\n",
      "Processing example 57000\n",
      "Processing example 58000\n",
      "Processing example 59000\n",
      "Building test set...\n",
      "Processing example 0\n",
      "Processing example 1000\n",
      "Processing example 2000\n",
      "Processing example 3000\n",
      "Processing example 4000\n",
      "Processing example 5000\n",
      "Processing example 6000\n",
      "Processing example 7000\n",
      "Processing example 8000\n",
      "Processing example 9000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "\n",
    "BST_PATH = 'BSR_bsds500.tgz'\n",
    "\n",
    "rand = np.random.RandomState(42)\n",
    "\n",
    "f = tarfile.open(BST_PATH)\n",
    "train_files = []\n",
    "for name in f.getnames():\n",
    "    if name.startswith('BSR/BSDS500/data/images/train/'):\n",
    "        train_files.append(name)\n",
    "\n",
    "print('Loading BSR training images')\n",
    "background_data = []\n",
    "for name in train_files:\n",
    "    try:\n",
    "        fp = f.extractfile(name)\n",
    "        bg_img = skimage.io.imread(fp)\n",
    "        background_data.append(bg_img)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "def compose_image(digit, background):\n",
    "    \"\"\"Difference-blend a digit and a random patch from a background image.\"\"\"\n",
    "    w, h, _ = background.shape\n",
    "    dw, dh, _ = digit.shape\n",
    "    x = np.random.randint(0, w - dw)\n",
    "    y = np.random.randint(0, h - dh)\n",
    "    \n",
    "    bg = background[x:x+dw, y:y+dh]\n",
    "    return np.abs(bg - digit).astype(np.uint8)\n",
    "\n",
    "\n",
    "def mnist_to_img(x):\n",
    "    \"\"\"Binarize MNIST digit and convert to RGB.\"\"\"\n",
    "    x = (x > 0).astype(np.float32)\n",
    "    d = x.reshape([28, 28, 1]) * 255\n",
    "    return np.concatenate([d, d, d], 2)\n",
    "\n",
    "\n",
    "def create_mnistm(X):\n",
    "    \"\"\"\n",
    "    Give an array of MNIST digits, blend random background patches to\n",
    "    build the MNIST-M dataset as described in\n",
    "    http://jmlr.org/papers/volume17/15-239/15-239.pdf\n",
    "    \"\"\"\n",
    "    X_ = np.zeros([X.shape[0], 28, 28, 3], np.uint8)\n",
    "    for i in range(X.shape[0]):\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print('Processing example', i)\n",
    "\n",
    "        bg_img = rand.choice(background_data)\n",
    "\n",
    "        d = mnist_to_img(X[i])\n",
    "        d = compose_image(d, bg_img)\n",
    "        X_[i] = d\n",
    "\n",
    "    return X_\n",
    "\n",
    "print('Building train set...')\n",
    "train = create_mnistm(x_train)\n",
    "print('Building test set...')\n",
    "test = create_mnistm(x_test)\n",
    "# Save dataset as pickle\n",
    "with open('mnistm_data.pkl', 'wb') as f:\n",
    "    pkl.dump({ 'train': train, 'test': test}, f, pkl.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
